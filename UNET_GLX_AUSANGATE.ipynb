{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNET_GLX_AUSANGATE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0xOYy8gxN1i",
        "colab_type": "text"
      },
      "source": [
        "<center>\n",
        "<h1>Estimación de Área Glaciar utilizando Redes Neuronales Convolucionales U-Net en Imágenes Multiespectrales Sentinel 2 en el Glaciar Ausangate, 2019 </h1>\n",
        "</center>\n",
        "\n",
        "Este Codigo esta Inspirado en la presentacion de [Chris Brown & Nick Clinton EarthEngine + Tensorflow presentation,2018](https://www.youtube.com/watch?v=w-1xfF0IaeU). y el Repositorio GitHub publicado por [Cesar Aybar, 2019](https://github.com/csaybar/EEwPython/blob/master/cnn_demo.ipynb)\n",
        "\n",
        "```\n",
        "Modificado por :  Percy Elbis Colque Caillahua\n",
        "Email : percyelbis@hotmail.com\n",
        "Fecha : 28/07/2019\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YIUU4Xzfm-N",
        "colab_type": "text"
      },
      "source": [
        "### 1. Instalar Librerias\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrZboinybQto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q tf-nightly-2.0-preview # tensorflow 2.0\n",
        "!pip install earthengine-api==0.1.175 # earthengine API\n",
        "!pip install -U -q PyDrive # Interact with Google drive\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6_5QeN_gZh0",
        "colab_type": "text"
      },
      "source": [
        "### 2.  Importar Librerias.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEP-G9o7gYq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GCS and Google Drive.\n",
        "from google.colab import auth\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive \n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Earth Engine Python API.\n",
        "import ee \n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Makes it easy to visualize data.\n",
        "import folium\n",
        "\n",
        "# Define the URL format used for Earth Engine generated map tiles.\n",
        "EE_TILES = 'https://earthengine.googleapis.com/map/{mapid}/{{z}}/{{x}}/{{y}}?token={token}'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWnZhQhWgPjE",
        "colab_type": "text"
      },
      "source": [
        "### 3. Autenticacion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pmv0szv4vhs2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GCS and Google Drive.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxad71Q6gTXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GEE.\n",
        "!earthengine authenticate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPEKvxed1uuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ee.Initialize()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67e58br00Xrr",
        "colab_type": "text"
      },
      "source": [
        "### 4. Funciones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76cRK5b3-3Oa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mapdisplay: Display ee.Features and ee.Images using folium.\n",
        "\n",
        "def Mapdisplay(center, dicc, Tiles=\"OpensTreetMap\",zoom_start=10):\n",
        "    '''\n",
        "    :param center: Center of the map (Latitude and Longitude).\n",
        "    :param dicc: Earth Engine Geometries or Tiles dictionary\n",
        "    :param Tiles: Mapbox Bright,Mapbox Control Room,Stamen Terrain,Stamen Toner,stamenwatercolor,cartodbpositron.\n",
        "    :zoom_start: Initial zoom level for the map.\n",
        "    :return: A folium.Map object.\n",
        "    '''\n",
        "    mapViz = folium.Map(location=center,tiles=Tiles, zoom_start=zoom_start)\n",
        "    for k,v in dicc.items():\n",
        "      if ee.image.Image in [type(x) for x in v.values()]:\n",
        "        folium.TileLayer(\n",
        "            tiles = EE_TILES.format(**v),\n",
        "            attr  = 'Google Earth Engine',\n",
        "            overlay =True,\n",
        "            name  = k\n",
        "          ).add_to(mapViz)\n",
        "      else:\n",
        "        folium.GeoJson(\n",
        "        data = v,\n",
        "        name = k\n",
        "          ).add_to(mapViz)\n",
        "    mapViz.add_child(folium.LayerControl()) # Lista de Layers.\n",
        "    mapViz.save(outfile='map.html') # Save the map.\n",
        "    return mapViz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U01lsbmchIgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Funcion\n",
        "'''\n",
        " * Function to mask clouds using the Sentinel-2 QA band.\n",
        " * Referencia : https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2.\n",
        " * Parametros : Image Sentinel-2 --->>> Nivel 2A.\n",
        " * Return : Devuelve los datos enmascarados y escalados, sin las bandas de control de calidad.\n",
        "'''\n",
        "def maskS2clouds(img):\n",
        "  # Pixel QA band.\n",
        "  qa = img.select('QA60')\n",
        "  # Bits 10 and 11 are clouds and cirrus, respectively.\n",
        "  cloudBitMask = (1 << 10)\n",
        "  cirrusBitMask = (1 << 11)\n",
        "  # Get the pixel QA band.\n",
        "  \n",
        "  # Both flags should be set to zero, indicating clear conditions.\n",
        "  mask = qa.bitwiseAnd(cloudBitMask).eq(0)\\\n",
        "           .And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
        "  return img.updateMask(mask)\\\n",
        "            .divide(10000)\\\n",
        "            .copyProperties(img, [\"system:time_start\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAfl6ABygYVr",
        "colab_type": "text"
      },
      "source": [
        "### 5. Preparar Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTcFXVBRQ8RN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#---Datos de Entrenamiento/Validacion.\n",
        "# Importar dataset de Entrenamiento y Validacion.\n",
        "train_glaciar = ee.FeatureCollection('users/torchi_12/train_dataset_2019') \n",
        "test_glaciar = ee.FeatureCollection('users/torchi_12/test_dataset_2019')\n",
        "\n",
        "# Display the train/test dataset\n",
        "db_glx = train_glaciar.merge(test_glaciar)\n",
        "center = db_glx.geometry().centroid().getInfo()['coordinates']\n",
        "center.reverse()\n",
        "#---Crear un Diccionario.\n",
        "dicc = {'train': train_glaciar.draw(**{'color': 'FF0000', 'strokeWidth': 5}).getMapId(),\n",
        "        'test' : test_glaciar.draw(**{'color': '0000FF', 'strokeWidth': 5}).getMapId(),\n",
        "       }\n",
        "\n",
        "#---Dataset Sentinel 2\n",
        "'''\n",
        "Sentinel-2 MSI: MultiSpectral Instrument, Level-2A\n",
        "Dataset Availability : 2017-03-28T00:00:00 - Present\n",
        "Referencia : https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR\n",
        "'''\n",
        "# Selecionar Bandas.\n",
        "bands = ['B12','B11','B8A','B8','B7','B6','B5','B4','B3','B2']\n",
        "# Mar 28, 2017 - Jul 11, 2019 Se tine el Nivel 2A.\n",
        "# En el area de entrenamiento solo se tiene desde 2018-12-13 hasta 2019-06-29.\n",
        "s2_sr = ee.ImageCollection(\"COPERNICUS/S2_SR\")\\\n",
        "               .filterBounds(db_glx)\\\n",
        "               .filterDate('2018-12-12', '2019-06-30')\\\n",
        "               .map(maskS2clouds)\\\n",
        "               .median()\n",
        "\n",
        "# Load target.\n",
        "target_glx = ee.Image('users/torchi_12/target_glx_s2').eq(1).rename('target')\n",
        "\n",
        "# Rename Bands.\n",
        "s2_msi = s2_sr.select(bands).rename(['SWIR2','SWIR1','RE4','NIR','RE3','RE2','RE1','R','G','B'])\n",
        "# Add Bands s2_ndsi,target.\n",
        "s2 = s2_msi.addBands(target_glx)\n",
        "#---Preparar Dataset para Visualizacion.\n",
        "from collections import OrderedDict\n",
        "## Target.\n",
        "target_glx_id = target_glx.getMapId()\n",
        "dicc['target_glx'] = target_glx_id\n",
        "\n",
        "# Crear Parametros de Visualizacion.\n",
        "visParams_s2 = {    \n",
        "  'bands': ['SWIR1', 'NIR', 'R'],\n",
        "  'min': 0,\n",
        "  'max': 0.5,\n",
        "  'gamma': 1.4,\n",
        "}\n",
        "\n",
        "s2Mapid = s2.getMapId(visParams_s2)\n",
        "dicc['Sentinel2'] = s2Mapid\n",
        "\n",
        "# Change the dictionary order.\n",
        "key_order = ['target_glx','Sentinel2','train','test']\n",
        "dicc = OrderedDict((k, dicc[k]) for k in key_order)\n",
        "\n",
        "# Show.\n",
        "Mapdisplay(center,dicc,zoom_start=5)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miL46BHTq77U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "def saveCNN_batch(image, point,kernel_size,scale,FilePrefix, selectors,folder, bucket='tesis_dataset'):\n",
        "  \"\"\"\n",
        "    Export a dataset for semantic segmentation by batches\n",
        "  \n",
        "  Params:\n",
        "  ------\n",
        "    - image : ee.Image to get pixels from; must be scalar-valued.\n",
        "    - point : Points to sample over.\n",
        "    - kernel_size : The kernel specifying the shape of the neighborhood. Only fixed, square and rectangle kernels are supported.\n",
        "      Weights are ignored; only the shape of the kernel is used.\n",
        "    - scale : A nominal scale in meters of the projection to work in.\n",
        "    - FilePrefix : Cloud Storage object name prefix for the export.\n",
        "    - selector : Specified the properties to save.\n",
        "    - bucket : The name of a Cloud Storage bucket for the export.  \n",
        "  \"\"\"\n",
        "  print('Found Cloud Storage bucket.' if tf.io.gfile.exists('gs://' + bucket) \n",
        "    else 'Output Cloud Storage bucket does not exist.')\n",
        "  \n",
        "  # Download the points (Server -> Client)\n",
        "  nbands = len(selectors)\n",
        "  points = train_glaciar.geometry().getInfo()['coordinates']    \n",
        "  nfeatures = kernel_size*kernel_size*nbands*len(points) #estimate the totals # of features\n",
        "     \n",
        "  image_neighborhood = image.neighborhoodToArray(ee.Kernel.rectangle(kernel_size, kernel_size, 'pixels'))\n",
        "  filenames = []\n",
        "  \n",
        "  #Threshold considering the max number of features permitted to export.\n",
        "  if nfeatures > 3e6:\n",
        "    nparts = int(np.ceil(nfeatures/3e6))\n",
        "    print('Dataset too long, splitting it into '+ str(nparts),'equal parts.')\n",
        "    \n",
        "    nppoints = np.array(points)\n",
        "    np.random.shuffle(nppoints)\n",
        "    \n",
        "    count_batch = 1  # Batch counter \n",
        "    \n",
        "    for batch_arr in np.array_split(nppoints,nparts):\n",
        "      \n",
        "      fcp = ee.FeatureCollection([\n",
        "          ee.Feature(ee.Geometry.Point(p),{'class':'NA'}) \n",
        "          for p in batch_arr.tolist() \n",
        "      ])\n",
        "      \n",
        "      # GLX dataset (fcp-points) collocation to each S2 grid cell value.\n",
        "      train_db = image_neighborhood.sampleRegions(collection=fcp, scale=scale)\n",
        "      filename = '%s/%s-%04d_' % (folder,FilePrefix,count_batch)\n",
        "      \n",
        "      # Create the tasks for passing of GEE to Google storage\n",
        "      print('sending the task #%04d'%count_batch)\n",
        "      Task = ee.batch.Export.table.toCloudStorage(\n",
        "        collection=train_db,        \n",
        "        selectors=selectors,          \n",
        "        description='Export batch '+str(count_batch),\n",
        "        fileNamePrefix=filename,\n",
        "        bucket=bucket,  \n",
        "        fileFormat='TFRecord')\n",
        "      \n",
        "      Task.start()\n",
        "      filenames.append(filename)\n",
        "      count_batch+=1\n",
        "      \n",
        "      while Task.active():\n",
        "        print('Polling for task (id: {}).'.format(Task.id))\n",
        "        time.sleep(3)\n",
        "        \n",
        "    return filenames\n",
        "  \n",
        "  else:    \n",
        "    train_db = image_neighborhood.sampleRegions(collection=points, scale=scale)         \n",
        "    Task = ee.batch.Export.table.toCloudStorage(\n",
        "      collection=train_db,\n",
        "      selectors=selectors,\n",
        "      description='Training Export',\n",
        "      fileNamePrefix=FilePrefix,\n",
        "      bucket=bucket,  \n",
        "      fileFormat='TFRecord')\n",
        "    Task.start()\n",
        "    \n",
        "    while Task.active():\n",
        "      print('Polling for task (id: {}).'.format(Task.id))\n",
        "      time.sleep(3)\n",
        "    \n",
        "    return FilePrefix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWd_BSgOPgXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "selectors = ['SWIR2','SWIR1','RE4','NIR','RE3','RE2','RE1','R','G','B','target']\n",
        "train_filenames = saveCNN_batch(s2,train_glaciar,128,10,'trainUNET', selectors,folder ='unet', bucket='tesis_dataset')\n",
        "test_filenames = saveCNN_batch(s2,test_glaciar,128,10,'testUNET', selectors,folder ='unet', bucket='tesis_dataset')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeFmmhoKdngc",
        "colab_type": "text"
      },
      "source": [
        "### 6. Creating a tf.data.Dataset from a TFRecord file\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8szRwsIxf7dc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fullname train/test db\n",
        "folder = 'unet'\n",
        "bucket = 'tesis_dataset'\n",
        "\n",
        "filesList = !gsutil ls 'gs://'{bucket}'/'{folder}\n",
        "\n",
        "trainFilePrefix = 'trainUNET'\n",
        "trainFilePath = [s for s in filesList if trainFilePrefix in s]\n",
        "\n",
        "\n",
        "testFilePrefix = 'testUNET'\n",
        "testFilePath = [s for s in filesList if testFilePrefix in s]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxN8c3C4f7LX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def input_fn(fileNames, numEpochs=None, shuffle=True, batchSize=16, side = 257):\n",
        "  # Read `TFRecordDatasets` \n",
        "  dataset = tf.data.TFRecordDataset(fileNames, compression_type='GZIP')\n",
        "\n",
        "  # Names of the features \n",
        "  feature_columns = {\n",
        "    'SWIR2' : tf.io.FixedLenFeature([side,side], dtype=tf.float32),\n",
        "    'SWIR1' : tf.io.FixedLenFeature([side,side], dtype=tf.float32),\n",
        "    'RE4': tf.io.FixedLenFeature([side,side], dtype=tf.float32),\n",
        "    'NIR' : tf.io.FixedLenFeature([side,side], dtype=tf.float32),\n",
        "    'RE3': tf.io.FixedLenFeature([side,side], dtype=tf.float32),\n",
        "    'RE2': tf.io.FixedLenFeature([side,side], dtype=tf.float32),\n",
        "    'RE1': tf.io.FixedLenFeature([side,side], dtype=tf.float32),\n",
        "    'R': tf.io.FixedLenFeature([side,side], dtype=tf.float32),  \n",
        "    'G': tf.io.FixedLenFeature([side,side], dtype=tf.float32),  \n",
        "    'B': tf.io.FixedLenFeature([side,side], dtype=tf.float32),\n",
        "    'target': tf.io.FixedLenFeature([side, side], dtype=tf.float32)\n",
        "  }\n",
        "  # Make a parsing function\n",
        "  def parse(example_proto):\n",
        "    parsed_features = tf.io.parse_single_example(example_proto, feature_columns)   \n",
        "    # passing of 257x257 to 256x256\n",
        "    parsed_features = {key:value[1:side,1:side] for key,value in parsed_features.items()} \n",
        "    # Separate the class labels from the training features\n",
        "    labels = parsed_features.pop('target')\n",
        "    return parsed_features, tf.cast(labels, tf.float32)\n",
        "  \n",
        "  # Passing of FeatureColumns to a 4D tensor\n",
        "  def stack_images(features,label):         \n",
        "    nfeat = tf.transpose(tf.squeeze(tf.stack(list(features.values()))))\n",
        "    nlabel = (tf.transpose(label))[:,:,tf.newaxis]\n",
        "    return nfeat, nlabel\n",
        "  \n",
        "  dataset = dataset.map(parse, num_parallel_calls=4)\n",
        "  dataset = dataset.map(stack_images, num_parallel_calls=4)\n",
        "  \n",
        "  if shuffle:\n",
        "    dataset = dataset.shuffle(buffer_size = batchSize * 10)\n",
        "  dataset = dataset.batch(batchSize)\n",
        "  dataset = dataset.repeat(numEpochs)\n",
        "  \n",
        "  return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j35NLEL-odZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dba = input_fn(trainFilePath,100,True,3)\n",
        "test_dba = input_fn(testFilePath, numEpochs=1, batchSize=1, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oN8D5r9ZiWJ",
        "colab_type": "text"
      },
      "source": [
        "### 7. Visualizar\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOExwdgKMSwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "display_num = 5\n",
        "plt.figure(figsize=(14, 21))\n",
        "\n",
        "c=0\n",
        "for i in range(1, display_num):\n",
        "  for x in test_dba.take(i):\n",
        "    x  \n",
        "  tensor = tf.squeeze(x[0]).numpy()[:,:,[3,1,0]]\n",
        "  target = tf.squeeze(x[1])\n",
        "\n",
        "  # print(target.sum())  \n",
        "  plt.subplot(display_num, 2, c + 1)\n",
        "  plt.imshow(tensor)\n",
        "  plt.title(\"RGB SENTINEL 2\")\n",
        "  \n",
        "  plt.subplot(display_num, 2, c + 2)\n",
        "  plt.imshow(target)\n",
        "  plt.title(\"Glx Area\")\n",
        "  c+=2 \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQtj9XZlzXPs",
        "colab_type": "text"
      },
      "source": [
        "### 8. Preparar Entrada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elSaqNk0zgnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Definir la Forma de la Imagen de Entrada.\n",
        "IMG_SHAPE  = (256, 256, 10)\n",
        "EPOCHS = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Koi4qoKSrH79",
        "colab_type": "text"
      },
      "source": [
        "### 9. Modelo U-Net\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBE-enutdivk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "def conv_block(input_tensor, num_filters):\n",
        "  encoder = layers.Conv2D(num_filters, (3, 3), padding='same')(input_tensor) # Los filtros son 3x3--->Capa  de Convolucion\n",
        "  encoder = layers.BatchNormalization()(encoder) # Capa de Normalizacion\n",
        "  encoder = layers.Activation('relu')(encoder) # Capa de Activacion\n",
        "  encoder = layers.Conv2D(num_filters, (3, 3), padding='same')(encoder)\n",
        "  encoder = layers.BatchNormalization()(encoder)\n",
        "  encoder = layers.Activation('relu')(encoder)\n",
        "  return encoder\n",
        "\n",
        "def encoder_block(input_tensor, num_filters):\n",
        "  encoder = conv_block(input_tensor, num_filters)\n",
        "  encoder_pool = layers.MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n",
        "  \n",
        "  return encoder_pool, encoder\n",
        "\n",
        "def decoder_block(input_tensor, concat_tensor, num_filters):\n",
        "  decoder = layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n",
        "  decoder = layers.concatenate([concat_tensor, decoder], axis=-1)\n",
        "  decoder = layers.BatchNormalization()(decoder)\n",
        "  decoder = layers.Activation('relu')(decoder)\n",
        "  decoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
        "  decoder = layers.BatchNormalization()(decoder)\n",
        "  decoder = layers.Activation('relu')(decoder)\n",
        "  decoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
        "  decoder = layers.BatchNormalization()(decoder)\n",
        "  decoder = layers.Activation('relu')(decoder)\n",
        "  return decoder\n",
        "\n",
        "inputs = layers.Input(shape=IMG_SHAPE)\n",
        "# 256\n",
        "encoder0_pool, encoder0 = encoder_block(inputs, 32)\n",
        "# 128\n",
        "encoder1_pool, encoder1 = encoder_block(encoder0_pool, 64)\n",
        "# 64\n",
        "encoder2_pool, encoder2 = encoder_block(encoder1_pool, 128)\n",
        "# 32\n",
        "encoder3_pool, encoder3 = encoder_block(encoder2_pool, 256)\n",
        "# 16\n",
        "encoder4_pool, encoder4 = encoder_block(encoder3_pool, 512)\n",
        "# 8\n",
        "center = conv_block(encoder4_pool, 1024)\n",
        "# center\n",
        "decoder4 = decoder_block(center, encoder4, 512)\n",
        "# 16\n",
        "decoder3 = decoder_block(decoder4, encoder3, 256)\n",
        "# 32\n",
        "decoder2 = decoder_block(decoder3, encoder2, 128)\n",
        "# 64\n",
        "decoder1 = decoder_block(decoder2, encoder1, 64)\n",
        "# 128\n",
        "decoder0 = decoder_block(decoder1, encoder0, 32)\n",
        "# 256\n",
        "\n",
        "outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(decoder0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VN8823C57Awb",
        "colab_type": "text"
      },
      "source": [
        "### 10. Define your model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCKDMdr0oXrf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import models\n",
        "model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whk-_nGeg5n0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the model.summary()\n",
        "from contextlib import redirect_stdout\n",
        "\n",
        "with open('modelsummary.txt', 'w') as f:\n",
        "    with redirect_stdout(f):\n",
        "        model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_9COoW_WjaT",
        "colab_type": "text"
      },
      "source": [
        "### 11. Defining custom metrics and loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brYb-GZjol4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import losses\n",
        "\n",
        "def dice_coeff(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    # Flatten\n",
        "    y_true_f = tf.reshape(y_true, [-1])\n",
        "    y_pred_f = tf.reshape(y_pred, [-1])\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "    score = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
        "    return score\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    loss = 1 - dice_coeff(y_true, y_pred)\n",
        "    return loss\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "  loss = losses.binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wdena4gnWz8y",
        "colab_type": "text"
      },
      "source": [
        "### 12. Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9689nduoufT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compilamos el Modelo.\n",
        "model.compile(optimizer='adam', loss=bce_dice_loss, metrics=[dice_loss,'accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spMWcCik7jYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veYd02szW_Zs",
        "colab_type": "text"
      },
      "source": [
        "### 13. Entrenar el Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq9ospifovNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "# Callbacks time\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "es = EarlyStopping(monitor='val_loss', patience=10)\n",
        "mcp = ModelCheckpoint(filepath='UNet_Glx.h5', monitor='val_loss', save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eSGDteJFLdu",
        "colab_type": "code",
        "outputId": "f07292f8-029f-4de4-d43e-9d96bf826f66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/ \n",
        "# remove  carpeta\n",
        "!rm UNet_Glx.h5 #rm fichero"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'UNet_Glx.h5': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eMm-mxWo9-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Entrenamiento Opcional ya se tiene un modelo pre-entrenado guardado en google drive.####\n",
        "N_train = 1883\n",
        "# Validacion\n",
        "N_test = 1470\n",
        "\n",
        "# Tamaño de Lote.\n",
        "batch_size = 10\n",
        "\n",
        "# Train the model.\n",
        "history = model.fit(train_dba,\n",
        "                    validation_data=test_dba,\n",
        "                    steps_per_epoch= int(np.ceil(N_train / float(batch_size))),\n",
        "                    validation_steps= int(np.ceil(N_test / float(batch_size))),\n",
        "                    epochs=EPOCHS,\n",
        "                    callbacks=[tensorboard_callback,es,mcp])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "es8Y2pVpYXM8",
        "colab_type": "code",
        "outputId": "eee82008-9a24-4b4f-cc24-3468f22ea2f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8LbBwm7qmqK",
        "colab_type": "code",
        "outputId": "95f3bae1-b1e1-4680-d20c-bb3887716547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div id=\"root\"></div>\n",
              "    <script>\n",
              "      (function() {\n",
              "        window.TENSORBOARD_ENV = window.TENSORBOARD_ENV || {};\n",
              "        window.TENSORBOARD_ENV[\"IN_COLAB\"] = true;\n",
              "        document.querySelector(\"base\").href = \"https://localhost:6007\";\n",
              "        function fixUpTensorboard(root) {\n",
              "          const tftb = root.querySelector(\"tf-tensorboard\");\n",
              "          // Disable the fragment manipulation behavior in Colab. Not\n",
              "          // only is the behavior not useful (as the iframe's location\n",
              "          // is not visible to the user), it causes TensorBoard's usage\n",
              "          // of `window.replace` to navigate away from the page and to\n",
              "          // the `localhost:<port>` URL specified by the base URI, which\n",
              "          // in turn causes the frame to (likely) crash.\n",
              "          tftb.removeAttribute(\"use-hash\");\n",
              "        }\n",
              "        function executeAllScripts(root) {\n",
              "          // When `script` elements are inserted into the DOM by\n",
              "          // assigning to an element's `innerHTML`, the scripts are not\n",
              "          // executed. Thus, we manually re-insert these scripts so that\n",
              "          // TensorBoard can initialize itself.\n",
              "          for (const script of root.querySelectorAll(\"script\")) {\n",
              "            const newScript = document.createElement(\"script\");\n",
              "            newScript.type = script.type;\n",
              "            newScript.textContent = script.textContent;\n",
              "            root.appendChild(newScript);\n",
              "            script.remove();\n",
              "          }\n",
              "        }\n",
              "        function setHeight(root, height) {\n",
              "          // We set the height dynamically after the TensorBoard UI has\n",
              "          // been initialized. This avoids an intermediate state in\n",
              "          // which the container plus the UI become taller than the\n",
              "          // final width and cause the Colab output frame to be\n",
              "          // permanently resized, eventually leading to an empty\n",
              "          // vertical gap below the TensorBoard UI. It's not clear\n",
              "          // exactly what causes this problematic intermediate state,\n",
              "          // but setting the height late seems to fix it.\n",
              "          root.style.height = `${height}px`;\n",
              "        }\n",
              "        const root = document.getElementById(\"root\");\n",
              "        fetch(\".\")\n",
              "          .then((x) => x.text())\n",
              "          .then((html) => void (root.innerHTML = html))\n",
              "          .then(() => fixUpTensorboard(root))\n",
              "          .then(() => executeAllScripts(root))\n",
              "          .then(() => setHeight(root, 800));\n",
              "      })();\n",
              "    </script>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdzwjkkbMEeI",
        "colab_type": "text"
      },
      "source": [
        "### 14. Cargar el modelo pre-entrenado(20 epochs)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbfWXUPxoLK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the Model Pre-Entrenado of the GooGle Drive\n",
        "file_obj =drive.CreateFile({'id':'1_1M9_zziF753YSVWEx3nKFZx0uJJtglk'}) # Desde Google Drive.\n",
        "file_obj.GetContentFile('UNet_Glx.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jJtpiYtVfwz",
        "colab_type": "code",
        "outputId": "f34be80a-47cb-41e3-bdb1-69676f70dff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# Load el Modelo entrenado.\n",
        "\n",
        "model.load_weights(\"UNet_Glx.h5\")\n",
        "model.evaluate(x = test_dba)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0901 17:54:21.995866 140057857267584 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1052/1052 [==============================] - 905s 861ms/step - loss: 0.0839 - dice_loss: 0.0286 - accuracy: 0.9788\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0839330828562733, 0.028609747, 0.9788186]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l08s8WgjhIEj",
        "colab_type": "text"
      },
      "source": [
        "### 15. Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsTUm835MSZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Area Glaciar a Predecir.\n",
        "xmin,ymin,xmax,ymax = [-71.2895576800648882,-13.8284791303437160, -71.1695138486407046,-13.7602836898167542]\n",
        "\n",
        "# Qgis Extension \n",
        "#-71.2895576800648882,-13.8284791303437160 : -71.1695138486407046,-13.7602836898167542---> Ausangate\n",
        "#-70.8966675314120351,-13.9960341865535920 : -70.7458947766221655,-13.8373832645521784---> Quelccaya\n",
        "#-77.6893128297523248,-9.1858434409387861 : -77.5221655263183607,-9.0342021137613369---> Huascaran\n",
        "#-73.04705802581952,-50.4798111720673,-72.73120109222577,-50.310848619751894--->Perito\n",
        "# Passing a rectangle (prediction area) to Earth Engine\n",
        "ausangate = ee.Geometry.Rectangle([xmin,ymin,xmax,ymax])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHlz8ffpK8GN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Desde Asset\n",
        "'''\n",
        "s2 = ee.Image('users/torchi_12/dat_s2/subset_6_of_S2A_MSIL2A_20190803T145731_N0213_R039_T19LBE_20190803T191158_resampled').multiply(0.0001)\n",
        "sencor = ['b10','b9','b8','b7','b6','b5','b4','b3','b2','b1']\n",
        "\n",
        "# renombrar bandas.\n",
        "s2p = s2.select(sencor).rename(['SWIR2','SWIR1','RE4','NIR','RE3','RE2','RE1','R','G','B'])\n",
        "#Fecha\n",
        "formato = '20190803'\n",
        "print(formato)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKe0xaMchKO_",
        "colab_type": "code",
        "outputId": "38be948a-a003-43dd-d541-1502d1d895b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Desde GEE\n",
        "s2 = ee.Image('COPERNICUS/S2_SR/20190818T145729_20190818T150545_T19LBE')\n",
        "# Normalizando 0-1\n",
        "s2_msi = s2.multiply(0.0001)\n",
        "# Renombrar bandas.\n",
        "s2p = s2_msi.select(bands).rename(['SWIR2','SWIR1','RE4','NIR','RE3','RE2','RE1','R','G','B'])\n",
        "# Extraer la Fecha.\n",
        "date = ee.Date(s2.get('system:time_start'))\n",
        "fechasat= date.format('YMd').getInfo()\n",
        "print(fechasat)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unxNYJeAkT0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputBucket = 'tesis_dataset'\n",
        "imageFilePrefix = 'unet/Predict_Glx_ausangate2019819'\n",
        "\n",
        "# Specify patch and file dimensions.\n",
        "imageExportFormatOptions = {\n",
        "  'patchDimensions': [256, 256],\n",
        "  'compressed': True\n",
        "}\n",
        "\n",
        "# Setup the task.\n",
        "imageTask = ee.batch.Export.image.toCloudStorage(\n",
        "  image=s2p,\n",
        "  description='Image Export',\n",
        "  fileNamePrefix=imageFilePrefix,\n",
        "  bucket=outputBucket,\n",
        "  scale=10,\n",
        "  fileFormat='TFRecord',\n",
        "# Ampliamos el area de estudio a un buffer 3km.\n",
        "  region = ausangate.buffer(3000).getInfo()['coordinates'],\n",
        "  #region = ausangate.getInfo()['coordinates'],\n",
        "  formatOptions=imageExportFormatOptions,\n",
        ")\n",
        "\n",
        "imageTask.start()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmXlRNgCl7YS",
        "colab_type": "code",
        "outputId": "f26af2fc-a434-493c-ba6f-a2c42ff867ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "import time \n",
        "while imageTask.active():\n",
        "  print('Polling for task (id: {}).'.format(imageTask.id))\n",
        "  time.sleep(5)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Polling for task (id: ZY4OBZFIFFLYBBCLBYXHKYJS).\n",
            "Polling for task (id: ZY4OBZFIFFLYBBCLBYXHKYJS).\n",
            "Polling for task (id: ZY4OBZFIFFLYBBCLBYXHKYJS).\n",
            "Polling for task (id: ZY4OBZFIFFLYBBCLBYXHKYJS).\n",
            "Polling for task (id: ZY4OBZFIFFLYBBCLBYXHKYJS).\n",
            "Polling for task (id: ZY4OBZFIFFLYBBCLBYXHKYJS).\n",
            "Polling for task (id: ZY4OBZFIFFLYBBCLBYXHKYJS).\n",
            "Polling for task (id: ZY4OBZFIFFLYBBCLBYXHKYJS).\n",
            "Polling for task (id: ZY4OBZFIFFLYBBCLBYXHKYJS).\n",
            "Polling for task (id: ZY4OBZFIFFLYBBCLBYXHKYJS).\n",
            "Polling for task (id: ZY4OBZFIFFLYBBCLBYXHKYJS).\n",
            "Polling for task (id: ZY4OBZFIFFLYBBCLBYXHKYJS).\n",
            "Polling for task (id: ZY4OBZFIFFLYBBCLBYXHKYJS).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dnsh-wb8mAyT",
        "colab_type": "code",
        "outputId": "0b7531e1-f435-4820-8a0f-eaf89bdb4f8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "filesList = !gsutil ls 'gs://'{outputBucket}'/unet/'\n",
        "exportFilesList = [s for s in filesList if imageFilePrefix in s]\n",
        "\n",
        "# Get the list of image files and the JSON mixer file.\n",
        "imageFilesList = []\n",
        "jsonFile = None\n",
        "for f in exportFilesList:\n",
        "  if f.endswith('.tfrecord.gz'):\n",
        "    imageFilesList.append(f)\n",
        "  elif f.endswith('.json'):\n",
        "    jsonFile = f\n",
        "\n",
        "# Make sure the files are in the right order.\n",
        "print(jsonFile)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gs://tesis_dataset/unet/Predict_Glx_ausangate2019819.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNnZ6W-9m50c",
        "colab_type": "code",
        "outputId": "bebaaf1f-07be-498b-8ec0-a45936e5b2c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "import json\n",
        "from pprint import pprint \n",
        "# Mixer contiene Metadat y Georeferenciacion\n",
        "# Load the contents of the mixer file to a JSON object.\n",
        "jsonText = !gsutil cat {jsonFile}\n",
        "# Get a single string w/ newlines from the IPython.utils.text.SList\n",
        "mixer = json.loads(jsonText.nlstr)\n",
        "pprint(mixer)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'patchDimensions': [256, 256],\n",
            " 'patchesPerRow': 7,\n",
            " 'projection': {'affine': {'doubleMatrix': [10.0,\n",
            "                                            0.0,\n",
            "                                            249420.0,\n",
            "                                            0.0,\n",
            "                                            -10.0,\n",
            "                                            8480720.0]},\n",
            "                'crs': 'EPSG:32719'},\n",
            " 'totalPatches': 35}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0DR0wlim83X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_input_fn(fileNames,side,bands):\n",
        "  \n",
        "  # Read `TFRecordDatasets` \n",
        "  dataset = tf.data.TFRecordDataset(fileNames, compression_type='GZIP')\n",
        "\n",
        "  featuresDict = {x:tf.io.FixedLenFeature([side, side], dtype=tf.float32) for x in bands}\n",
        "     \n",
        "  # Make a parsing function\n",
        "  def parse_image(example_proto):\n",
        "    parsed_features = tf.io.parse_single_example(example_proto, featuresDict)\n",
        "    return parsed_features\n",
        "  \n",
        "  def stack_images(features):         \n",
        "    nfeat = tf.transpose(tf.squeeze(tf.stack(list(features.values()))))    \n",
        "    return nfeat\n",
        "  dataset = dataset.map(parse_image, num_parallel_calls=4)\n",
        "  dataset = dataset.map(stack_images, num_parallel_calls=4)   \n",
        "  dataset = dataset.batch(side*side)\n",
        "\n",
        "  return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnRFSIpCfjD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_db = predict_input_fn(fileNames=imageFilesList,side=256,bands=['SWIR2','SWIR1','RE4','NIR','RE3','RE2','RE1','R','G','B'])\n",
        "predictions = model.predict(predict_db)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdepemIOVnD-",
        "colab_type": "code",
        "outputId": "f26833e5-80f7-4603-a04e-34031019d707",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        }
      },
      "source": [
        "# Instantiate the writer.\n",
        "PATCH_WIDTH , PATCH_HEIGHT = [256,256]\n",
        "outputImageFile = 'gs://' + outputBucket + '/unet/GlxAusangate.TFRecord'\n",
        "writer = tf.io.TFRecordWriter(outputImageFile)\n",
        "\n",
        "# Every patch-worth of predictions we'll dump an example into the output\n",
        "# file with a single feature that holds our predictions. Since our predictions\n",
        "# are already in the order of the exported data, the patches we create here\n",
        "# will also be in the right order.\n",
        "curPatch = 1\n",
        "for  prediction in predictions:\n",
        "  patch = prediction.squeeze().T.flatten().tolist()\n",
        "  \n",
        "  if (len(patch) == PATCH_WIDTH * PATCH_HEIGHT):\n",
        "    print('Done with patch ' + str(curPatch) + '...')    \n",
        "    # Create an example\n",
        "    example = tf.train.Example(\n",
        "      features=tf.train.Features(\n",
        "        feature={\n",
        "          'glx_prob': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch))\n",
        "        }\n",
        "      )\n",
        "    )\n",
        "    \n",
        "    writer.write(example.SerializeToString())    \n",
        "    curPatch += 1 \n",
        "\n",
        "writer.close()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done with patch 1...\n",
            "Done with patch 2...\n",
            "Done with patch 3...\n",
            "Done with patch 4...\n",
            "Done with patch 5...\n",
            "Done with patch 6...\n",
            "Done with patch 7...\n",
            "Done with patch 8...\n",
            "Done with patch 9...\n",
            "Done with patch 10...\n",
            "Done with patch 11...\n",
            "Done with patch 12...\n",
            "Done with patch 13...\n",
            "Done with patch 14...\n",
            "Done with patch 15...\n",
            "Done with patch 16...\n",
            "Done with patch 17...\n",
            "Done with patch 18...\n",
            "Done with patch 19...\n",
            "Done with patch 20...\n",
            "Done with patch 21...\n",
            "Done with patch 22...\n",
            "Done with patch 23...\n",
            "Done with patch 24...\n",
            "Done with patch 25...\n",
            "Done with patch 26...\n",
            "Done with patch 27...\n",
            "Done with patch 28...\n",
            "Done with patch 29...\n",
            "Done with patch 30...\n",
            "Done with patch 31...\n",
            "Done with patch 32...\n",
            "Done with patch 33...\n",
            "Done with patch 34...\n",
            "Done with patch 35...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlgDx1cGp0WM",
        "colab_type": "code",
        "outputId": "a02d4e03-c0f7-4b9b-cc4e-64a3bcf661ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "## Upload the classifications to an EE asset.\n",
        "!gsutil ls -l {outputImageFile}"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   9176650  2019-09-01T18:36:43Z  gs://tesis_dataset/unet/GlxAusangate.TFRecord\n",
            "TOTAL: 1 objects, 9176650 bytes (8.75 MiB)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqB8MS6oWixT",
        "colab_type": "code",
        "outputId": "c8833f3e-933b-4ae5-c977-3b712a29d79c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# REPLACE WITH YOUR USERNAME:\n",
        "USER_NAME = 'torchi_12'\n",
        "outputAssetID = 'users/' + USER_NAME + '/GlxAusangate_' + fechasat\n",
        "print('Writing to ' + outputAssetID)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing to users/torchi_12/GlxAusangate_2019818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jP2wvhZyxxN",
        "colab_type": "text"
      },
      "source": [
        "###  16. Resultados GCS a GEE Asset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LLazXQgWn85",
        "colab_type": "code",
        "outputId": "c293ac5d-6ca4-47cb-aefa-4f064fe138b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Start the upload. It step might take a while.\n",
        "!earthengine upload image --asset_id={outputAssetID} {outputImageFile} {jsonFile}"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Started upload task with ID: EZABJANW33BNCSKTO3NBCXXP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbfPqdqLbfig",
        "colab_type": "code",
        "outputId": "2bcaf6f3-298b-4520-ee76-6e2ad18b8a1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 858
        }
      },
      "source": [
        "## Display the Results.\n",
        "ProbsImage = ee.Image(outputAssetID)\n",
        "predictionsImage = ee.Image(outputAssetID).gte(0.500)\n",
        "dicc = {'GlxProbability':ProbsImage.getMapId({'min':0.49,'max':0.498}),\n",
        "        'Glx':predictionsImage.getMapId(),\n",
        "       'S2_RGB': s2p.getMapId(visParams_s2)}\n",
        "\n",
        "center = ausangate.centroid().getInfo()['coordinates']\n",
        "center.reverse()\n",
        "\n",
        "Mapdisplay(center=center,dicc=dicc,zoom_start=13)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,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\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ],
            "text/plain": [
              "<folium.folium.Map at 0x7f617a519470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWnL8saj9kLH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
